<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Full Document Preprocessing Workflow</title>
    <style>
        body {
            font-family: sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 900px;
            margin: auto;
            background: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba(0,0,0,0.1);
        }
        h1, h2 {
            color: #0056b3;
            text-align: center;
            margin-bottom: 20px;
        }
        .stage {
            border: 2px solid #0056b3;
            border-radius: 8px;
            padding: 20px;
            margin-bottom: 30px;
            background-color: #f8f9fa;
        }
        .stage h2 {
            margin-top: 0;
            color: #0056b3;
            border-bottom: 2px solid #b3d7ff;
            padding-bottom: 10px;
            text-align: left;
        }
        .phase {
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
            background-color: #e9f5ff;
        }
        .phase h3 {
            margin-top: 0;
            color: #003d80;
            border-bottom: 1px solid #b3d7ff;
            padding-bottom: 5px;
        }
        .step {
            margin-bottom: 12px;
            padding-left: 25px;
            position: relative;
        }
        .step::before {
            content: '➤'; /* Use a different marker */
            position: absolute;
            left: 0;
            color: #007bff;
            font-weight: bold;
            font-size: 1.1em;
        }
         .sub-step {
            margin-left: 20px;
            margin-bottom: 8px;
            padding-left: 20px;
            position: relative;
            font-size: 0.95em;
        }
        .sub-step::before {
            content: '↳';
            position: absolute;
            left: 0;
            color: #17a2b8;
        }
        .io {
            font-style: italic;
            color: #555;
            margin-left: 25px; /* Align with step text */
            display: block;
            margin-top: 5px;
            margin-bottom: 8px;
            font-size: 0.9em;
        }
        .io strong {
            color: #333;
        }
        .arrow {
            text-align: center;
            font-size: 24px;
            color: #0056b3;
            margin: 15px 0;
        }
        code {
            background-color: #eee;
            padding: 2px 4px;
            border-radius: 3px;
            font-family: monospace;
            color: #c7254e; /* Bootstrap code color */
        }
        ul {
            list-style: none;
            padding-left: 0;
        }
        li {
            margin-bottom: 8px;
        }
        .note {
            font-size: 0.9em;
            color: #6c757d;
            margin-top: 10px;
            margin-left: 25px;
            border-left: 3px solid #ccc;
            padding-left: 10px;
        }
        .status {
            font-weight: bold;
            margin-left: 10px;
            font-size: 0.85em;
        }
        .status-completed { color: #28a745; }
        .status-planned { color: #ffc107; }

    </style>
</head>
<body>
    <div class="container">
        <h1>Full Document Preprocessing & Enhancement Workflow</h1>
        <p>This document outlines the complete pipeline for processing PDF documents into structured, enhanced chunks suitable for database ingestion and analysis.</p>

        <!-- Stage 1: Chunk Creation -->
        <div class="stage">
            <h2>Stage 1: Chunk Creation <span class="status status-completed">(Completed)</span></h2>
            <p><strong>Goal:</strong> Convert raw PDF documents into meaningful, structured text chunks.</p>

            <div class="phase">
                <h3>1.0: Initial PDF Inspection</h3>
                 <span class="step">Inspect PDF Pages (<code>0_inspect_pdf_pages.py</code>)</span>
                 <span class="io"><strong>Input:</strong> Raw PDF document.</span>
                 <span class="io"><strong>Output:</strong> Analysis/understanding of PDF structure (metadata, page layouts).</span>
                 <p class="note">Optional preliminary step for understanding document characteristics.</p>
            </div>

            <div class="arrow">⬇</div>

            <div class="phase">
                <h3>1.1: Structure Identification</h3>
                 <span class="step">Extract Chapters (<code>1_extract_chapters_to_json.py</code>)</span>
                 <span class="io"><strong>Input:</strong> Raw PDF document.</span>
                 <span class="io"><strong>Output:</strong> JSON file defining chapter titles and page ranges.</span>
                 <br/>
                 <span class="step">Identify Sections & Merge Blocks (<code>2_identify_sections_and_merge.py</code>)</span>
                 <span class="io"><strong>Input:</strong> PDF document, Chapter JSON.</span>
                 <span class="io"><strong>Output:</strong> Intermediate representation with text blocks merged and assigned section hierarchies.</span>
            </div>

             <div class="arrow">⬇</div>

            <div class="phase">
                <h3>1.2: Content Extraction & Initial Chunking</h3>
                 <span class="step">Extract Page Content (<code>3_extract_page_content.py</code>)</span>
                 <span class="io"><strong>Input:</strong> PDF document.</span>
                 <span class="io"><strong>Output:</strong> Raw text content extracted per page, potentially associated with identified structures.</span>
                 <br/>
                 <span class="step">Create Initial Chunks</span>
                 <span class="io"><strong>Input:</strong> Merged text blocks with section info, Page content.</span>
                 <span class="io"><strong>Output:</strong> Initial set of text chunks based on section boundaries.</span>
                 <p class="note">This step combines outputs from previous steps to form preliminary chunks.</p>
            </div>

            <div class="arrow">⬇</div>

            <div class="phase">
                <h3>1.3: Chunk Refinement</h3>
                 <span class="step">Split Large Sections/Chunks (<code>4_split_large_sections.py</code>)</span>
                 <span class="io"><strong>Input:</strong> Initial chunks.</span>
                 <span class="io"><strong>Output:</strong> Chunks, ensuring none exceed a maximum size threshold.</span>
                 <br/>
                 <span class="step">Merge Small Chunks (<code>5_merge_small_chunks.py</code>)</span>
                 <span class="io"><strong>Input:</strong> Chunks (potentially after splitting).</span>
                 <span class="io"><strong>Output:</strong> Finalized chunks for Stage 1 (<code>2E_final_merged_chunks</code>), ensuring none are below a minimum size threshold.</span>
            </div>
        </div>

        <!-- Stage 2: GPT Enhancement -->
        <div class="stage">
             <h2>Stage 2: GPT Enhancement <span class="status status-planned">(Planned)</span></h2>
             <p><strong>Goal:</strong> Enrich the created chunks with summaries, tags, standard references, and importance scores using an LLM.</p>

            <div class="phase">
                <h3>2.1: Chapter-Level Analysis (<code>7_generate_chapter_details.py</code>)</h3>
                <p><strong>Goal:</strong> Generate high-level summary and tags for each chapter.</p>
                <ul>
                    <li>
                        <span class="step">Load & Group Chunks:</span>
                        <span class="io"><strong>Input:</strong> Finalized chunks from Stage 1 (<code>2E_final_merged_chunks</code>).</span>
                    </li>
                    <li>
                        <span class="step">Reconstruct Chapter Text & Check Size:</span> Combine chunks, add markers, check against token limits.
                    </li>
                    <li>
                        <span class="step">Process Chapter (LLM Call):</span>
                        <div class="sub-step">If within limit: Single API call (tool: <code>extract_chapter_details</code>) for summary & tags.</div>
                        <div class="sub-step">If exceeds limit: Iterative segmentation, passing previous summary/tags for refinement.</div>
                    </li>
                    <li>
                        <span class="step">Save Chapter Details:</span>
                        <span class="io"><strong>Output:</strong> Chapter details JSON (<code>3A_chapter_details/chapter_{num}_details.json</code>).</span>
                    </li>
                </ul>
            </div>

            <div class="arrow">⬇</div>

            <div class="phase">
                <h3>2.2: Section-Level Analysis (Planned)</h3>
                <p><strong>Goal:</strong> Generate specific details (summary, tags, standard) for each section.</p>
                 <ul>
                    <li>
                        <span class="step">Iterate Sections:</span> Loop through sections within each chapter.
                    </li>
                    <li>
                        <span class="step">Reconstruct Section Text:</span> Combine chunks for the section.
                    </li>
                    <li>
                        <span class="step">Build Prompt & Call LLM:</span> Include section text and chapter context (from 2.1). Request section summary, tags, standard, codes.
                    </li>
                    <li>
                         <span class="step">Store Section Details:</span>
                         <span class="io"><strong>Output:</strong> Temporary storage mapping section ID to its details.</span>
                    </li>
                </ul>
            </div>

            <div class="arrow">⬇</div>

            <div class="phase">
                <h3>2.3: Chunk-Level Analysis & Final Assembly (Planned)</h3>
                 <p><strong>Goal:</strong> Generate final chunk details and assemble the complete chunk JSON.</p>
                 <ul>
                    <li>
                        <span class="step">Iterate Chunks:</span> Loop through individual chunks (from <code>2E_final_merged_chunks</code>).
                    </li>
                    <li>
                        <span class="step">Build Prompt & Call LLM:</span> Include chunk content and section context (from 2.2). Request chunk summary, importance score, references.
                    </li>
                    <li>
                        <span class="step">Assemble Final Chunk:</span> Combine original chunk data, generated details (summary, importance, refs), and inherited section details (tags, standard, codes). Add other required fields (embeddings, IDs etc. - potentially outside LLM).
                    </li>
                    <li>
                        <span class="step">Save Final Enhanced Chunk:</span>
                        <span class="io"><strong>Output:</strong> Fully populated chunk JSON (e.g., <code>2F_gpt_enhanced_chunks/chunk_{id}.json</code>).</span>
                    </li>
                </ul>
            </div>
        </div>

        <h2>End Result</h2>
        <p>The final output is a directory (e.g., <code>2F_gpt_enhanced_chunks</code>) containing JSON files for each chunk, fully populated according to the defined schema and enriched with LLM-generated context, ready for database ingestion.</p>

    </div>
</body>
</html>
