# -*- coding: utf-8 -*-
"""
Stage 2: Section Identification & Enrichment

Purpose:
Processes chapter data generated by Stage 1. It identifies logical sections
within each chapter based on Markdown headings (H1-H6). For each section, it
calculates token count, determines start/end page numbers, and uses an LLM
to generate a concise summary, tags, applicable standard(s), standard codes,
an importance score, and references.

Input: JSON file from Stage 1 (e.g., 'pipeline_output/stage1/stage1_chapter_data.json').
Output: A JSON file in OUTPUT_DIR containing a list of section dictionaries.
        (e.g., 'pipeline_output/stage2/stage2_section_data.json')
"""

import os
import json
import traceback
import re
import time
import logging
import requests
from pathlib import Path
from typing import List, Dict, Tuple, Any, Optional, Union
from collections import defaultdict

# --- Dependencies Check ---
try:
    import tiktoken
except ImportError:
    tiktoken = None
    print("WARNING: tiktoken not installed. Token counts will be estimated (chars/4). `pip install tiktoken`")

try:
    import natsort
except ImportError:
    natsort = None
    print("INFO: natsort not installed. Chapters/Sections might not sort naturally. `pip install natsort`")

try:
    from openai import OpenAI, APIError
except ImportError:
    OpenAI = None
    APIError = None
    print("ERROR: openai library not installed. GPT features unavailable. `pip install openai`")

try:
    from tqdm import tqdm
except ImportError:
    tqdm = lambda x, **kwargs: x # Make tqdm optional
    print("INFO: tqdm not installed. Progress bars disabled. `pip install tqdm`")

# ==============================================================================
# Configuration
# ==============================================================================

# --- Directory Paths ---
# TODO: Adjust these paths as needed
STAGE1_OUTPUT_DIR = "pipeline_output/stage1"
STAGE1_FILENAME = "stage1_chapter_data.json"
OUTPUT_DIR = "pipeline_output/stage2"
OUTPUT_FILENAME = "stage2_section_data.json"
LOG_DIR = "pipeline_output/logs"

# --- API Configuration ---
# TODO: Load securely or replace placeholders (Ensure consistency with Stage 1)
BASE_URL = os.environ.get("OPENAI_API_BASE", "https://api.example.com/v1")
MODEL_NAME_CHAT = os.environ.get("OPENAI_MODEL_CHAT", "gpt-4-turbo-nonp")
OAUTH_URL = os.environ.get("OAUTH_URL", "https://api.example.com/oauth/token")
CLIENT_ID = os.environ.get("OAUTH_CLIENT_ID", "your_client_id")
CLIENT_SECRET = os.environ.get("OAUTH_CLIENT_SECRET", "your_client_secret")
SSL_SOURCE_PATH = os.environ.get("SSL_SOURCE_PATH", "/path/to/your/rbc-ca-bundle.cer")
SSL_LOCAL_PATH = "/tmp/rbc-ca-bundle.cer"

# --- API Parameters ---
MAX_COMPLETION_TOKENS_SECTION = 2000 # Max tokens for section details response
TEMPERATURE = 0.3
API_RETRY_ATTEMPTS = 3
API_RETRY_DELAY = 5 # seconds
MAX_RECENT_SUMMARIES_CONTEXT = 5 # Number of previous section summaries to include in context

# --- Token Cost (Optional) ---
PROMPT_TOKEN_COST = 0.01
COMPLETION_TOKEN_COST = 0.03

# --- Logging Setup ---
Path(LOG_DIR).mkdir(parents=True, exist_ok=True)
# Use a different log file for this stage
log_file = Path(LOG_DIR) / 'stage2_section_processing.log'
# Remove existing handlers if configuring multiple times in a notebook
for handler in logging.root.handlers[:]:
    logging.root.removeHandler(handler)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)

# ==============================================================================
# Utility Functions (Self-Contained, adapted from Stage 1 and original scripts)
# ==============================================================================

# --- Tokenizer ---
_TOKENIZER = None
if tiktoken:
    try:
        _TOKENIZER = tiktoken.get_encoding("cl100k_base")
        logging.info("Using 'cl100k_base' tokenizer via tiktoken.")
    except Exception as e:
        logging.warning(f"Failed to initialize tiktoken tokenizer: {e}. Falling back to estimate.")
        _TOKENIZER = None

def count_tokens(text: str) -> int:
    """Counts tokens using tiktoken if available, otherwise estimates (chars/4)."""
    if not text: return 0
    if _TOKENIZER:
        try: return len(_TOKENIZER.encode(text))
        except Exception: return len(text) // 4
    else: return len(text) // 4

# --- API Client ---
_SSL_CONFIGURED = False
_OPENAI_CLIENT = None

def _setup_ssl(source_path=SSL_SOURCE_PATH, local_path=SSL_LOCAL_PATH) -> bool:
    """Copies SSL cert locally and sets environment variables."""
    global _SSL_CONFIGURED
    if _SSL_CONFIGURED: return True
    if not Path(source_path).is_file():
         logging.warning(f"SSL source certificate not found at {source_path}. API calls may fail.")
         _SSL_CONFIGURED = True
         return True
    logging.info("Setting up SSL certificate...")
    try:
        source = Path(source_path); local = Path(local_path)
        local.parent.mkdir(parents=True, exist_ok=True)
        with open(source, "rb") as sf, open(local, "wb") as df: df.write(sf.read())
        os.environ["SSL_CERT_FILE"] = str(local)
        os.environ["REQUESTS_CA_BUNDLE"] = str(local)
        logging.info(f"SSL certificate configured successfully at: {local}")
        _SSL_CONFIGURED = True
        return True
    except Exception as e:
        logging.error(f"Error setting up SSL certificate: {e}", exc_info=True)
        return False

def _get_oauth_token(oauth_url=OAUTH_URL, client_id=CLIENT_ID, client_secret=CLIENT_SECRET, ssl_verify_path=SSL_LOCAL_PATH) -> Optional[str]:
    """Retrieves OAuth token."""
    verify_path = ssl_verify_path if Path(ssl_verify_path).exists() else True
    logging.info("Attempting to get OAuth token...")
    payload = {'grant_type': 'client_credentials', 'client_id': client_id, 'client_secret': client_secret}
    try:
        response = requests.post(oauth_url, data=payload, timeout=30, verify=verify_path)
        response.raise_for_status()
        token_data = response.json(); oauth_token = token_data.get('access_token')
        if not oauth_token: logging.error("Error: 'access_token' not found."); return None
        logging.info("OAuth token obtained successfully.")
        return oauth_token
    except requests.exceptions.RequestException as e:
        logging.error(f"Error getting OAuth token: {e}", exc_info=True); return None

def get_openai_client(base_url=BASE_URL) -> Optional[OpenAI]:
    """Initializes and returns the OpenAI client."""
    global _OPENAI_CLIENT
    if _OPENAI_CLIENT: return _OPENAI_CLIENT
    if not OpenAI: logging.error("OpenAI library not available."); return None
    if not _setup_ssl(): logging.warning("Proceeding without explicit SSL setup.")
    api_key = _get_oauth_token()
    if not api_key: logging.error("Aborting client creation due to OAuth token failure."); return None
    try:
        _OPENAI_CLIENT = OpenAI(api_key=api_key, base_url=base_url)
        logging.info("OpenAI client created successfully.")
        return _OPENAI_CLIENT
    except Exception as e:
        logging.error(f"Error creating OpenAI client: {e}", exc_info=True); return None

# --- API Call (Single Attempt) ---
# Renamed from _call_gpt_with_retry to reflect single attempt nature
def _call_gpt_single_attempt(client, model, messages, max_tokens, temperature, tools=None, tool_choice=None):
    """Makes a single API call attempt."""
    logging.debug("Making single API call attempt...")
    completion_kwargs = {"model": model, "messages": messages, "max_tokens": max_tokens, "temperature": temperature, "stream": False}
    if tools and tool_choice:
        completion_kwargs["tools"] = tools; completion_kwargs["tool_choice"] = tool_choice
        logging.debug("Making API call with tool choice...")
    else:
        # This function now expects tool use based on how get_section_details_from_gpt uses it
        if not tools or not tool_choice:
             logging.warning("API call initiated without explicit tool choice - this function expects tool use.")
        completion_kwargs["tools"] = tools # Still send tools if provided
        # completion_kwargs["response_format"] = {"type": "json_object"} # Use if not using tools

    # No try/except here, let exceptions propagate up to the caller (get_section_details_from_gpt)
    response = client.chat.completions.create(**completion_kwargs)
    logging.debug("API call successful.")
    response_message = response.choices[0].message; usage_info = response.usage

    if response_message.tool_calls:
        tool_call = response_message.tool_calls[0]
        # Basic validation can still happen here or be deferred to parser
        if tool_choice and isinstance(tool_choice, dict):
            expected_tool_name = tool_choice.get("function", {}).get("name")
            if expected_tool_name and tool_call.function.name != expected_tool_name:
                raise ValueError(f"Expected tool '{expected_tool_name}' but received '{tool_call.function.name}'")
        return tool_call.function.arguments, usage_info # Return JSON string from tool arguments
    elif response_message.content:
        # If content is returned instead of tool_calls, return it for the parser to handle
        logging.warning("API response contained content instead of expected tool_calls.")
        return response_message.content, usage_info
    else:
        raise ValueError("API response missing both tool calls and content.")

def parse_gpt_json_response(response_content_str: str, expected_keys: List[str]) -> Optional[Dict]:
    """Parses JSON response string from GPT and validates expected keys. Raises exceptions on failure."""
    # Removed the unnecessary try block
    if response_content_str.strip().startswith("```json"): response_content_str = response_content_str.strip()[7:-3].strip()
    elif response_content_str.strip().startswith("```"): response_content_str = response_content_str.strip()[3:-3].strip()
    data = json.loads(response_content_str)
    # Corrected indentation for the following lines
    if not isinstance(data, dict): raise ValueError("Response is not a JSON object.")
    missing_keys = [key for key in expected_keys if key not in data]
    if missing_keys: raise ValueError(f"Missing expected keys: {', '.join(missing_keys)}")
    logging.debug("GPT JSON response parsed successfully.")
    return data
    # Let exceptions propagate up to the caller (get_section_details_from_gpt)
    # except json.JSONDecodeError as e:
    #     logging.error(f"Error decoding GPT JSON: {e}\nRaw response: {response_content_str[:500]}..."); return None
    # except ValueError as e:
    #     logging.error(f"Error validating GPT JSON: {e}\nRaw response: {response_content_str[:500]}..."); return None

# --- File/Path Utils ---
def create_directory(directory: str):
    """Creates the specified directory if it does not already exist."""
    Path(directory).mkdir(parents=True, exist_ok=True)

# --- Page Tag Extraction (Identical to Stage 1) ---
PAGE_NUMBER_TAG_PATTERN = re.compile(r'<!--\s*PageNumber="(\d+)"\s*-->')
AZURE_TAG_PATTERN = re.compile(r'<!--\s*Page(Footer|Number|Break|Header)=?(".*?"|\d+)?\s*-->\s*\n?')

def clean_azure_tags(text: str) -> str:
    """Removes Azure Document Intelligence specific HTML comment tags."""
    return AZURE_TAG_PATTERN.sub("", text)

def extract_page_mapping(content: str) -> list[tuple[int, int]]:
    """Extracts (character_position, page_number) tuples from tags."""
    mapping = []; raw_matches = []
    for match in PAGE_NUMBER_TAG_PATTERN.finditer(content):
        raw_matches.append((match.start(), int(match.group(1))))
    if not raw_matches: return []
    raw_matches.sort(key=lambda x: (x[0], -x[1]))
    if raw_matches:
        mapping.append(raw_matches[0])
        for i in range(1, len(raw_matches)):
            if raw_matches[i][0] > mapping[-1][0]: mapping.append(raw_matches[i])
    if mapping and mapping[-1][0] < len(content):
        mapping.append((len(content), mapping[-1][1]))
    return mapping

def get_section_page_range(raw_section_slice: str, chapter_start_page: int) -> Tuple[int, int]:
    """Determines start/end page for a section slice."""
    section_mapping = extract_page_mapping(raw_section_slice)
    if not section_mapping:
        # If no tags within the section, assume it's on the chapter's start page
        # This might be inaccurate if sections span pages without internal tags.
        logging.debug("No page tags found within section slice. Using chapter start page.")
        return chapter_start_page, chapter_start_page
    else:
        # Use the first and last page numbers found *within the slice*
        start_page = section_mapping[0][1]
        end_page = section_mapping[-1][1]
        end_page = max(start_page, end_page) # Ensure end >= start
        logging.debug(f"Section page range derived from tags: {start_page}-{end_page}")
        return start_page, end_page

# --- Section Identification ---
def find_headings(raw_content: str) -> list[dict]:
    """Finds Markdown headings (levels 1-6) in raw text."""
    heading_pattern = re.compile(r"^(#{1,6})\s+(.+)$", re.MULTILINE)
    headings = []
    for match in heading_pattern.finditer(raw_content):
        headings.append({
            "level": len(match.group(1)),
            "text": match.group(2).strip(),
            "position": match.start()
        })
    # Add virtual end marker
    headings.append({"level": 0, "text": "DOCUMENT_END", "position": len(raw_content)})
    headings.sort(key=lambda h: h["position"])
    return headings

def split_chapter_into_sections(chapter_data: dict) -> list[dict]:
    """Splits raw chapter content into initial sections based on headings."""
    raw_content = chapter_data["raw_content"]
    headings = find_headings(raw_content)
    initial_sections = []
    section_index_in_chapter = 0
    current_heading_context = {f"level_{i}": None for i in range(1, 7)}
    # Initialize L1 with chapter name for context
    current_heading_context["level_1"] = chapter_data.get("chapter_name")

    # Handle content before the first heading
    first_heading_pos = headings[0]['position'] if headings and headings[0]['level'] > 0 else len(raw_content)
    if first_heading_pos > 0:
        intro_slice = raw_content[:first_heading_pos].strip()
        if intro_slice:
            section_index_in_chapter += 1
            initial_sections.append({
                "raw_section_slice": intro_slice,
                "level": 1, # Assign level 1 conceptually
                "section_title": chapter_data.get("chapter_name", "Introduction"), # Use chapter name
                "start_pos": 0,
                "end_pos": first_heading_pos,
                "section_number": section_index_in_chapter,
                "level_1": chapter_data.get("chapter_name"),
            })

    # Process sections defined by headings
    for i in range(len(headings) - 1):
        current_heading = headings[i]
        next_heading = headings[i + 1]

        # Skip if level is 0 (e.g., the intro section we might have handled)
        if current_heading["level"] == 0: continue

        section_start_pos = current_heading["position"]
        section_end_pos = next_heading["position"]
        raw_section_slice = raw_content[section_start_pos:section_end_pos].strip()

        if raw_section_slice: # Only create section if content exists
            section_index_in_chapter += 1
            current_level = current_heading["level"]
            current_title = current_heading["text"]

            # Update heading context
            current_heading_context[f"level_{current_level}"] = current_title
            for lower_level in range(current_level + 1, 7):
                current_heading_context[f"level_{lower_level}"] = None

            section_data = {
                "raw_section_slice": raw_section_slice,
                "level": current_level,
                "section_title": current_title,
                "start_pos": section_start_pos, # Position relative to raw_content start
                "end_pos": section_end_pos,     # Position relative to raw_content start
                "section_number": section_index_in_chapter,
            }
            # Add current hierarchy context
            for level_num in range(1, 7):
                level_key = f"level_{level_num}"
                if current_heading_context.get(level_key):
                    section_data[level_key] = current_heading_context[level_key]

            initial_sections.append(section_data)

    return initial_sections

def generate_hierarchy_string(section_data: dict) -> str:
    """Generates a breadcrumb-style hierarchy string."""
    parts = []
    max_level_to_check = section_data.get("level", 6)
    for i in range(1, max_level_to_check + 1):
        level_key = f"level_{i}"
        heading_text = section_data.get(level_key)
        if heading_text: parts.append(heading_text)
        else: break # Stop if a level is missing
    return " > ".join(parts)

# --- GPT Prompting for Section Details ---
SECTION_TOOL_SCHEMA = {
    "type": "function",
    "function": {
        "name": "extract_section_details",
        "description": "Extracts detailed information about a specific document section based on its content and the overall chapter context.",
        "parameters": {
            "type": "object",
            "properties": {
                "section_summary": {
                    "type": "string",
                    "description": "A concise summary (1-3 sentences) capturing the core topic or purpose of this section, suitable for reranking search results."
                },
                "section_tags": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "A list of meaningful keywords or tags specific to this section's content, scaled appropriately to the section's length and complexity. These tags will be used as metadata for search reranking."
                },
                "section_standard": {
                    "type": "string",
                    "description": "The primary accounting or reporting standard applicable to this section (e.g., 'IFRS', 'US GAAP', 'N/A')."
                },
                "section_standard_codes": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "A list of specific standard codes explicitly mentioned or directly relevant in the section (e.g., ['IFRS 16', 'IAS 17']). The number of codes should reflect the section's content. These codes will be used as metadata for search reranking."
                },
                "section_importance_score": { # Matches field name in script 8's schema
                    "type": "number",
                    "description": "A score between 0.0 (low importance) and 1.0 (high importance) indicating how crucial this section is to understanding the overall chapter's topic. A score of 0.5 indicates average or unknown importance. This float value will be used for search reranking.",
                    "minimum": 0.0,
                    "maximum": 1.0
                },
                "section_references": {
                    "type": "array",
                    "items": {"type": "string"},
                    "description": "A list of explicit references to other sections, chapters, or standard codes found within this section's text (e.g., ['See Section 4.5', 'Refer to Chapter 3', 'IAS 36.12']). Provide an empty list [] if none are found. These references provide context."
                }
            },
            # Keep required field name as 'section_importance_score' to match script 8's schema
            "required": ["section_summary", "section_tags", "section_standard", "section_standard_codes", "section_importance_score", "section_references"]
        }
    }
}

def _build_section_prompt(section_text, chapter_summary, chapter_tags, previous_section_summaries=None):
    """Builds the messages list for the section processing call."""
    if previous_section_summaries is None: previous_section_summaries = []

    # System prompt from script 8
    system_prompt = """<role>You are an expert financial reporting specialist.</role>
<source_material>You are analyzing a specific section within a chapter from an EY technical accounting guidance manual. You are provided with the overall chapter summary/tags and summaries of recently processed sections from the same chapter.</source_material>
<task>Your primary task is to generate a **concise summary (1-3 sentences)** for the current section, suitable for use in reranking search results. Additionally, extract relevant tags, the primary applicable accounting standard, and specific standard codes mentioned. Use the 'extract_section_details' tool for your response.</task>
<guardrails>Base your analysis strictly on the provided section text and context. Focus on capturing the core topic/purpose concisely for the summary. Ensure tags and standard codes are precise and derived from the section text.</guardrails>"""

    user_prompt_elements = ["<prompt>"]
    # User prompt elements from script 8
    user_prompt_elements.append("<style>Concise, factual, keyword-focused for summary; technical and precise for other fields.</style>")
    user_prompt_elements.append("<tone>Professional, objective, expert.</tone>")
    user_prompt_elements.append("<audience>Accounting professionals needing specific guidance on this section.</audience>")
    user_prompt_elements.append('<response_format>Use the "extract_section_details" tool.</response_format>')

    user_prompt_elements.append("<overall_chapter_context>")
    user_prompt_elements.append(f"<chapter_summary>{chapter_summary}</chapter_summary>")
    user_prompt_elements.append(f"<chapter_tags>{json.dumps(chapter_tags)}</chapter_tags>")
    user_prompt_elements.append("</overall_chapter_context>")

    if previous_section_summaries:
        user_prompt_elements.append("<recent_section_context>")
        for i, summary in enumerate(previous_section_summaries):
            user_prompt_elements.append(f"<previous_section_{i+1}_summary>{summary}</previous_section_{i+1}_summary>")
        user_prompt_elements.append("</recent_section_context>")

    user_prompt_elements.append(f"<current_section_text>{section_text}</current_section_text>")

    # Instructions block from script 8 (includes 'section_importance' in point 5)
    user_prompt_elements.append("<instructions>")
    user_prompt_elements.append("""
    **Analysis Objective:** Analyze the provided <current_section_text> considering the <overall_chapter_context> and <recent_section_context> (if provided).
    **Action:** Generate the following details for the **current section** using the 'extract_section_details' tool:
    1.  **section_summary:** A **very concise summary (1-3 sentences)** capturing the core topic or purpose of this section. This summary will be used to help rerank search results, so it should be distinct and informative at a glance.
    2.  **section_tags:** Generate a list of meaningful, granular tags specific to THIS SECTION's content. The number of tags should be dynamic and reflect the section's complexity and key topics. These tags are crucial metadata for search reranking.
    3.  **section_standard:** Identify the single, primary accounting standard framework most relevant to THIS SECTION (e.g., 'IFRS', 'US GAAP', 'N/A').
    4.  **section_standard_codes:** List specific standard codes (e.g., 'IFRS 16', 'IAS 36.12', 'ASC 842-10-15') explicitly mentioned or directly and significantly relevant within THIS SECTION's text. The number of codes should be dynamic, reflecting the section's content. Provide an empty list [] if none are applicable. These codes are crucial metadata for search reranking.
    5.  **section_importance_score:** Assign a score between 0.0 (low importance) and 1.0 (high importance) representing how crucial this section's content is for understanding the overall topic of the chapter provided in the <overall_chapter_context>. Consider the section's scope and depth relative to the chapter summary. A score of 0.5 indicates average or unknown importance. Provide a float value (e.g., 0.7). This score will directly influence search result ranking.
    6.  **section_references:** List any explicit textual references made within the <current_section_text> to other sections, chapters, paragraphs, or specific standard codes (e.g., "See Section 4.5", "Refer to Chapter 3", "IAS 36.12"). Provide an empty list [] if no explicit references are found.
    """)
    user_prompt_elements.append("</instructions>")
    user_prompt_elements.append("</prompt>")
    user_prompt = "\n".join(user_prompt_elements)
    messages = [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}]
    return messages

def get_section_details_from_gpt(section_text: str, chapter_details: Dict, previous_summaries: List[str], client: OpenAI) -> Optional[Dict]:
    """Calls GPT to get structured details for a section."""
    messages = _build_section_prompt(
        section_text=section_text,
        chapter_summary=chapter_details.get('chapter_summary', 'N/A'),
        chapter_tags=chapter_details.get('chapter_tags', []),
        previous_section_summaries=previous_summaries
    )
    prompt_tokens_est = sum(count_tokens(msg["content"]) for msg in messages)
    logging.debug(f"Estimated prompt tokens for section enrichment: {prompt_tokens_est}")

    last_exception = None
    for attempt in range(API_RETRY_ATTEMPTS):
        try:
            logging.debug(f"Attempt {attempt + 1}/{API_RETRY_ATTEMPTS} to get and parse details for section...")
            # 1. Call API (single attempt)
            response_content_json_str, usage_info = _call_gpt_single_attempt(
                client, MODEL_NAME_CHAT, messages, MAX_COMPLETION_TOKENS_SECTION, TEMPERATURE,
                tools=[SECTION_TOOL_SCHEMA],
                tool_choice={"type": "function", "function": {"name": "extract_section_details"}}
            )
            if not response_content_json_str:
                raise ValueError("API call returned empty response content.")

            # 2. Parse Response (raises exception on failure)
            parsed_data = parse_gpt_json_response(
                response_content_json_str,
                expected_keys=["section_summary", "section_tags", "section_standard", "section_standard_codes", "section_importance_score", "section_references"]
            )

            # 3. Log usage and return data if successful
            if usage_info:
                 prompt_tokens = usage_info.prompt_tokens; completion_tokens = usage_info.completion_tokens
                 total_tokens = usage_info.total_tokens
                 total_cost = (prompt_tokens / 1000 * PROMPT_TOKEN_COST) + (completion_tokens / 1000 * COMPLETION_TOKEN_COST)
                 # Changed to DEBUG to reduce console noise
                 logging.debug(f"API Usage (Section Details) - Prompt: {prompt_tokens}, Completion: {completion_tokens}, Total: {total_tokens}, Cost: ${total_cost:.4f}")
            else:
                 logging.debug("Usage information not available.")

            return parsed_data # Success! Exit loop and return.

        except (APIError, requests.exceptions.RequestException) as e:
            logging.warning(f"API communication error on attempt {attempt + 1}: {e}")
            last_exception = e
            time.sleep(API_RETRY_DELAY * (attempt + 1)) # Exponential backoff for API errors
        except (json.JSONDecodeError, ValueError) as e:
             logging.warning(f"Parsing/Validation error on attempt {attempt + 1}: {e}")
             # Log raw response if possible (might be large)
             if 'response_content_json_str' in locals() and response_content_json_str:
                 logging.warning(f"Raw response snippet: {response_content_json_str[:500]}...")
             last_exception = e
             time.sleep(API_RETRY_DELAY) # Simple delay for parsing errors
        except Exception as e:
            logging.error(f"Unexpected error on attempt {attempt + 1}: {e}", exc_info=True)
            last_exception = e
            time.sleep(API_RETRY_DELAY) # Simple delay for unexpected errors

    # If loop finishes without returning, all attempts failed
    logging.error(f"Failed to get valid section details after {API_RETRY_ATTEMPTS} attempts.")
    if last_exception:
        logging.error(f"Last error encountered: {last_exception}")
    return None # Indicate failure

import sys # Ensure sys is imported

# ==============================================================================
# Main Stage 2 Logic
# ==============================================================================

# Helper function to create a unique ID for a section
def _create_section_id(section_data: Dict) -> Optional[str]:
    """Creates a unique identifier string for a section."""
    doc_id = section_data.get("document_id")
    chap_num = section_data.get("chapter_number")
    sec_num = section_data.get("section_number")
    if doc_id is not None and chap_num is not None and sec_num is not None:
        return f"{doc_id}::{chap_num}::{sec_num}"
    logging.warning(f"Could not create section ID from data: {section_data.get('section_title', 'Unknown Section')}")
    return None # Return None if essential parts are missing

def process_chapter_for_sections(
    chapter_data: Dict,
    client: Optional[OpenAI],
    existing_section_details: Dict[str, Dict] # Changed: Pass dict of existing details
    ) -> List[Dict]:
    """
    Identifies, enriches, and assembles section data for a single chapter.
    Retries sections if they exist in existing_section_details but lack enrichment.
    Returns a list of all section data dictionaries for this chapter (new, retried, or existing valid).
    """
    chapter_number = chapter_data.get("chapter_number", "UNKNOWN")
    document_id = chapter_data.get("document_id", "UNKNOWN_DOC") # Get doc_id for ID creation
    logging.info(f"Processing sections for Chapter {chapter_number}...")
    processed_chapter_sections = [] # Store all sections for this chapter
    recent_section_summaries = [] # Context for GPT within this chapter run

    initial_sections = split_chapter_into_sections(chapter_data)
    logging.info(f"  Identified {len(initial_sections)} initial sections for Chapter {chapter_number}.")
    skipped_fully_processed_count = 0
    retried_count = 0
    newly_processed_count = 0
    failed_processing_count = 0

    for section_raw_data in tqdm(initial_sections, desc=f"Chapter {chapter_number} Sections"):
        section_number = section_raw_data["section_number"]
        section_title = section_raw_data.get('section_title', 'Unknown Title')

        # Create ID for checking/storing
        temp_id_data = {"document_id": document_id, "chapter_number": chapter_number, "section_number": section_number}
        section_id = _create_section_id(temp_id_data)
        if not section_id:
            logging.warning(f"Could not generate ID for section {section_number} ('{section_title[:30]}...'). Skipping.")
            failed_processing_count += 1
            continue

        # --- Check existing data ---
        existing_record = existing_section_details.get(section_id)
        needs_processing = True
        if existing_record:
            # Check if enrichment exists (using section_summary as a proxy)
            if existing_record.get("section_summary") is not None:
                logging.debug(f"  Section {section_id} already processed with enrichment. Skipping.")
                processed_chapter_sections.append(existing_record) # Add existing valid record
                # Update context window even if skipped
                if existing_record.get("section_summary"):
                    recent_section_summaries.append(existing_record["section_summary"])
                skipped_fully_processed_count += 1
                needs_processing = False
            else:
                # Changed to DEBUG to reduce console noise
                logging.debug(f"  Section {section_id} found with missing enrichment. Retrying processing.")
                retried_count += 1
        else:
             logging.debug(f"  Section {section_id} not found in existing data. Processing as new.")
             newly_processed_count += 1

        if not needs_processing:
            continue # Go to next section in initial_sections

        # --- Process Section (New or Retry) ---
        logging.debug(f"  Processing Section {section_id} ('{section_title[:30]}...')")
        raw_slice = section_raw_data["raw_section_slice"]
        cleaned_content = clean_azure_tags(raw_slice)
        section_token_count = count_tokens(cleaned_content)

        if not cleaned_content.strip():
            logging.debug(f"  Skipping empty section {section_number} after cleaning.")
            continue

        # Determine section page range
        section_start_page, section_end_page = get_section_page_range(
            raw_slice, chapter_data.get("chapter_page_start", 0)
        )

        # Generate hierarchy string
        section_hierarchy = generate_hierarchy_string(section_raw_data)

        # Get GPT enrichment
        gpt_details = None
        if client:
            # Use only the last N summaries for context to limit prompt size
            context_summaries = recent_section_summaries[-MAX_RECENT_SUMMARIES_CONTEXT:]
            gpt_details = get_section_details_from_gpt(cleaned_content, chapter_data, context_summaries, client)
        else:
            logging.debug("  Skipping GPT enrichment (no client).")

        # Assemble final section data
        final_section_data = {
            # Carry over from chapter
            "document_id": chapter_data.get("document_id"),
            "chapter_number": chapter_number,
            "chapter_name": chapter_data.get("chapter_name"),
            "chapter_tags": chapter_data.get("chapter_tags"),
            "chapter_summary": chapter_data.get("chapter_summary"),
            "chapter_token_count": chapter_data.get("chapter_token_count"),
            # Section specific
            "section_number": section_number,
            "section_title": section_raw_data.get("section_title"),
            "section_hierarchy": section_hierarchy,
            "section_token_count": section_token_count,
            "section_start_page": section_start_page,
            "section_end_page": section_end_page,
            "cleaned_section_content": cleaned_content, # Pass cleaned content
            "raw_section_slice_start_pos": section_raw_data.get("start_pos"), # Pass raw positions
            "raw_section_slice_end_pos": section_raw_data.get("end_pos"),
            # From GPT (or defaults)
            "section_summary": gpt_details.get("section_summary", None) if gpt_details else None,
            "section_tags": gpt_details.get("section_tags", []) if gpt_details else [],
            "section_standard": gpt_details.get("section_standard", "N/A") if gpt_details else "N/A",
            "section_standard_codes": gpt_details.get("section_standard_codes", []) if gpt_details else [],
            "section_importance_score": gpt_details.get("section_importance_score", 0.5) if gpt_details else 0.5,
            "section_references": gpt_details.get("section_references", []) if gpt_details else [],
            # Add level_x hierarchy fields from raw data
            **{f"level_{i}": section_raw_data.get(f"level_{i}") for i in range(1, 7) if section_raw_data.get(f"level_{i}")}
        }
        processed_chapter_sections.append(final_section_data) # Add the processed data

        # Update recent summaries list for context (use summary from final_section_data)
        current_summary = final_section_data.get("section_summary")
        if current_summary: # Only add if enrichment was successful (not None)
            recent_section_summaries.append(current_summary)
            # Keep only the last N summaries
            if len(recent_section_summaries) > MAX_RECENT_SUMMARIES_CONTEXT:
                recent_section_summaries.pop(0)
        elif gpt_details is None: # Log if enrichment failed
             failed_processing_count += 1
             logging.warning(f"  Failed to get enrichment for section {section_id} after retries.")


    # Log chapter summary
    logging.info(f"  Chapter {chapter_number} Summary: Skipped={skipped_fully_processed_count}, Retried={retried_count}, New={newly_processed_count}, Failed={failed_processing_count}")
    return processed_chapter_sections # Return all sections processed/retrieved for this chapter


def run_stage2():
    """Main function to execute Stage 2 processing with resumability."""
    logging.info("--- Starting Stage 2: Section Identification & Enrichment ---")
    create_directory(OUTPUT_DIR)
    output_filepath = Path(OUTPUT_DIR) / OUTPUT_FILENAME

    # --- Load Existing Stage 2 Data (for Resumability) ---
    existing_section_details = {} # Store as dict: {section_id: section_data}
    if output_filepath.exists():
        try:
            with open(output_filepath, "r", encoding="utf-8") as f:
                existing_data_list = json.load(f)
            if not isinstance(existing_data_list, list):
                 logging.warning(f"Existing output file {output_filepath} does not contain a valid list. Starting fresh.")
            else:
                 # Populate the dictionary, creating IDs
                 count = 0
                 for sec_data in existing_data_list:
                     sec_id = _create_section_id(sec_data)
                     if sec_id:
                         existing_section_details[sec_id] = sec_data
                         count += 1
                 logging.info(f"Loaded {count} existing section records into map from {output_filepath}.")
        except json.JSONDecodeError:
            logging.error(f"Error decoding JSON from {output_filepath}. Starting fresh.", exc_info=True)
            existing_section_details = {}
        except Exception as e:
            logging.error(f"Error loading existing data from {output_filepath}: {e}. Starting fresh.", exc_info=True)
            existing_section_details = {}

    # --- Load Stage 1 Data ---
    stage1_output_file = Path(STAGE1_OUTPUT_DIR) / STAGE1_FILENAME
    if not stage1_output_file.exists():
        logging.error(f"Stage 1 output file not found: {stage1_output_file}. Cannot proceed.")
        # Exit if stage 1 data is missing
        sys.exit(f"Error: Stage 1 output file '{stage1_output_file}' not found.")
    try:
        with open(stage1_output_file, "r", encoding="utf-8") as f:
            all_chapter_data = json.load(f)
        logging.info(f"Loaded {len(all_chapter_data)} chapters from {stage1_output_file}")
    except Exception as e:
        logging.error(f"Error loading Stage 1 data from {stage1_output_file}: {e}", exc_info=True)
        # Exit if stage 1 data is unloadable
        sys.exit(f"Error: Failed to load Stage 1 data from '{stage1_output_file}'.")

    if not all_chapter_data:
        logging.warning("Stage 1 data is empty. No sections to process.")
        # Save the potentially loaded (but empty) existing data back
        try:
            with open(output_filepath, "w", encoding="utf-8") as f:
                # Save values from the map as a list
                json.dump(list(existing_section_details.values()), f, indent=2, ensure_ascii=False)
            logging.info(f"No chapters to process. Saved {len(existing_section_details)} existing section records back to {output_filepath}")
        except Exception as e:
            logging.error(f"Error saving output JSON to {output_filepath}: {e}", exc_info=True)
        return list(existing_section_details.values()) # Return list

    # --- Initialize OpenAI Client ---
    client = get_openai_client()
    if not client:
        logging.warning("OpenAI client initialization failed. Section enrichment will be skipped.")

    # --- Process Chapters for Sections ---
    all_processed_sections_list = [] # Collect results from all chapters here
    total_sections_processed_run = 0
    total_sections_failed_run = 0
    total_sections_skipped_run = 0

    for chapter_data in tqdm(all_chapter_data, desc="Processing Chapters for Sections"):
        # Pass the dictionary of existing details for checking/retrying
        chapter_results = process_chapter_for_sections(
            chapter_data, client, existing_section_details
        )
        all_processed_sections_list.extend(chapter_results)

        # Optional: Update counts based on logs/return values if needed for final summary
        # This requires process_chapter_for_sections to return counts or parse logs

    # --- Final Sort and Save ---
    logging.info("Performing final sort and save...")
    final_data_to_save = all_processed_sections_list # Already a list
    if natsort:
        try:
            # Sort by chapter then section number
            final_data_to_save = sorted(all_processed_sections_list, key=lambda x: (
                x.get('chapter_number', float('inf')),
                x.get('section_number', float('inf'))
            ))
            logging.info("Performed final sort of section data.")
        except Exception as final_sort_e:
            logging.warning(f"Could not perform final sort: {final_sort_e}. Saving potentially unsorted data.")
            # Keep final_data_to_save as the unsorted list
    else:
        logging.info("natsort not available, skipping final sort.")

    try:
        with open(output_filepath, "w", encoding="utf-8") as f:
            json.dump(final_data_to_save, f, indent=2, ensure_ascii=False)
        logging.info(f"Saved final data with {len(final_data_to_save)} section records to {output_filepath}")
    except Exception as e:
        logging.error(f"Error saving final output JSON to {output_filepath}: {e}", exc_info=True)


    # --- Print Summary ---
    final_record_count = len(final_data_to_save)
    # TODO: Enhance summary by tracking processed/failed/skipped counts more accurately if needed
    logging.info("--- Stage 2 Summary ---")
    logging.info(f"Total chapters from Stage 1: {len(all_chapter_data)}")
    logging.info(f"Total sections in final file : {final_record_count}")
    # Add more detailed counts here if implemented
    logging.info(f"Output JSON file             : {output_filepath}")
    logging.info("--- Stage 2 Finished ---")

    return final_data_to_save # Return the final data list

# ==============================================================================
# Main Execution Block
# ==============================================================================

if __name__ == "__main__":
    run_stage2()
